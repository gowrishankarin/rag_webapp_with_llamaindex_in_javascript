{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e7278ed-be83-4819-b74b-404364ee8a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "GROQ_SECRET = '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'\n",
    "FIREWORKS_SECRET = 'lIquLwxe1wJFVcPrcUBByclUyFpiKUOodwKCv3ANwzPeep9m'\n",
    "\n",
    "GROQ_ENDPOINT = 'https://api.groq.com/openai/v1/chat/completions'\n",
    "GROQ_MODEL = 'mixtral-8x7b-32768'\n",
    "\n",
    "FIREWORKS_MODEL = \"accounts/fireworks/models/mixtral-8x7b-instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20a92d3d-19c0-477f-838d-3e1ee1b1e414",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import httpx\n",
    "import asyncio\n",
    "import json\n",
    "from openai import OpenAI as Fireworks\n",
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "381c2903-4eeb-484f-9ecd-62f211152ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Result(BaseModel):\n",
    "    winner: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0300263f-66ba-4269-9d1d-31234ce4b7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "fireworks_client  = Fireworks(\n",
    "    base_url = \"https://api.fireworks.ai/inference/v1\",\n",
    "    api_key=FIREWORKS_SECRET,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27421f93-8bc5-45b2-82c4-6187d8a42525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='2a6daeef-d94f-4f43-bcf1-65cbb03c2bf3', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='{\\n\"winner\": \"Users and businesses of natural language processing (NLP) technologies and applications stand to benefit significantly from fast language models. These models can process and generate language in a matter of milliseconds or seconds, as opposed to slower models that may take several seconds or even minutes to produce results. Here are some reasons why fast language models are essential in today\\'s fast-paced digital world:\\n\\n1. Better user experience: In chatbots, search engines, and other NLP-driven interfaces, users expect quick responses to their queries. Slow model processing times can frustrate users and make them less likely to use these systems. Fast language models help maintain a natural, pleasant conversation or interaction flow.\\n\\n2. Real-time analytics: In applications like social media monitoring, sentiment analysis, and brand reputation management, organizations rely on instant insights to inform decisions. Slow models may lag behind real-time events, making analysis irrelevant or less accurate. Fast models enable timely and appropriate reactions.\\n\\n3. Scalability: Businesses utilizing faster language models can deploy their services and applications across larger user bases without worrying about scaling issues. Slower models can struggle with growing demand, leading to higher costs and decreased user satisfaction.\\n\\n4. Reduced computational costs: Faster models can process data more efficiently, which translates to lower computational costs and less reliance on power-intensive hardware. This makes them more accessible for smaller businesses and budget-conscious organizations.\\n\\n5. Integration with edge devices: With the rise of IoT devices, fast language models are necessary for seamless integration with these resource-constrained devices. Rapid response times and minimal processing power requirements enable better edge computing capabilities and a broader range of potential use cases.\\n\\n6. Competitive advantage: As NLP technologies become increasingly prevalent, fast models can create a competitive edge for businesses. By providing quicker, more efficient, and effective natural language capabilities, companies can differentiate themselves in their respective markets.\\n\\n7. Continual learning: As fast language models are deployed and gather insights from their interactions, they can quickly incorporate new knowledge and adapt to changing contexts or user needs. This iterative, dynamic learning process helps improve model performance and ensures relevance over time.\"\\n}', role='assistant', function_call=None, tool_calls=None))], created=1715152336, model='accounts/fireworks/models/mixtral-8x7b-instruct', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=476, prompt_tokens=21, total_tokens=497))\n",
      "\"{\\n\\\"winner\\\": \\\"Users and businesses of natural language processing (NLP) technologies and applications stand to benefit significantly from fast language models. These models can process and generate language in a matter of milliseconds or seconds, as opposed to slower models that may take several seconds or even minutes to produce results. Here are some reasons why fast language models are essential in today's fast-paced digital world:\\n\\n1. Better user experience: In chatbots, search engines, and other NLP-driven interfaces, users expect quick responses to their queries. Slow model processing times can frustrate users and make them less likely to use these systems. Fast language models help maintain a natural, pleasant conversation or interaction flow.\\n\\n2. Real-time analytics: In applications like social media monitoring, sentiment analysis, and brand reputation management, organizations rely on instant insights to inform decisions. Slow models may lag behind real-time events, making analysis irrelevant or less accurate. Fast models enable timely and appropriate reactions.\\n\\n3. Scalability: Businesses utilizing faster language models can deploy their services and applications across larger user bases without worrying about scaling issues. Slower models can struggle with growing demand, leading to higher costs and decreased user satisfaction.\\n\\n4. Reduced computational costs: Faster models can process data more efficiently, which translates to lower computational costs and less reliance on power-intensive hardware. This makes them more accessible for smaller businesses and budget-conscious organizations.\\n\\n5. Integration with edge devices: With the rise of IoT devices, fast language models are necessary for seamless integration with these resource-constrained devices. Rapid response times and minimal processing power requirements enable better edge computing capabilities and a broader range of potential use cases.\\n\\n6. Competitive advantage: As NLP technologies become increasingly prevalent, fast models can create a competitive edge for businesses. By providing quicker, more efficient, and effective natural language capabilities, companies can differentiate themselves in their respective markets.\\n\\n7. Continual learning: As fast language models are deployed and gather insights from their interactions, they can quickly incorporate new knowledge and adapt to changing contexts or user needs. This iterative, dynamic learning process helps improve model performance and ensures relevance over time.\\\"\\n}\"\n"
     ]
    }
   ],
   "source": [
    "response = fireworks_client.chat.completions.create(\n",
    "    model=FIREWORKS_MODEL,\n",
    "    response_format={\"type\": \"json_object\", \"schema\": Result.model_json_schema()},\n",
    "    messages=[{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Explain the importance of fast language models. Output in JSON format\",\n",
    "    }],\n",
    ")\n",
    "print(response)\n",
    "print(json.dumps(response.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "414f0a8d-11a8-4e77-b282-47b1024fdbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask(endpoint, model, token, question):\n",
    "    \n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"temperature\": 0.5,\n",
    "        \"max_tokens\": 4096,\n",
    "        \"messages\": question\n",
    "    }\n",
    "    \n",
    "    json_payload = json.dumps(payload)\n",
    "\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Accept\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {token}\"\n",
    "    }\n",
    "\n",
    "    response = requests.request(\"POST\", endpoint, headers=headers, data=json_payload)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        # Print the response content\n",
    "        response_json = response.json();\n",
    "        # print(response_json)\n",
    "        answer = response_json[\"choices\"][0][\"message\"][\"content\"];\n",
    "        answers = None\n",
    "        return { \"answers\": answer, \"status_code\": response.status_code}\n",
    "    else:\n",
    "        # Print an error message if the request failed\n",
    "        return { \n",
    "        \"status_code\": response.status_code,  \n",
    "        \"message\": response.text\n",
    "        }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9bc7c38-07f8-4c2a-b358-f170e3cd6ee6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answers': 'Fast language models are important for several reasons:\\n\\n1. Improved user experience: Fast language models can quickly process and generate language, providing a more responsive and fluid user experience. This is especially important in applications such as real-time chat, voice assistants, and language translation.\\n2. Scalability: Fast language models can handle a larger volume of requests and data, making them more scalable and suitable for use in large-scale applications.\\n3. Cost-effective: Fast language models can process language more efficiently, which can lead to cost savings in terms of computational resources and energy consumption.\\n4. Enabling real-time applications: Fast language models are essential for enabling real-time applications such as live speech-to-text transcription, real-time language translation, and real-time chat.\\n5. Advancing research: Fast language models enable researchers to process and analyze large amounts of data more quickly, leading to new insights and advances in natural language processing and machine learning.\\n\\nOverall, fast language models are important for improving the user experience, enabling real-time applications, and advancing research in natural language processing and machine learning.',\n",
       " 'status_code': 200}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = [{\"role\": \"user\", \"content\": \"Explain the importance of fast language models\"}]\n",
    "ask(GROQ_ENDPOINT, GROQ_MODEL, GROQ_SECRET, question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c5298c-c2fc-4da2-a7c9-88e6614810d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2695fc78-424c-415e-80bf-eb57b55de887",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def ask_async(endpoint, model, token, question):\n",
    "    \n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"temperature\": 0.5,\n",
    "        \"max_tokens\": 4096,\n",
    "        \"messages\": question\n",
    "    }\n",
    "    \n",
    "    json_payload = json.dumps(payload)\n",
    "\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Accept\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {token}\"\n",
    "    }\n",
    "\n",
    "    async with httpx.AsyncClient() as client:\n",
    "        response = await client.post(endpoint, headers=headers, data=json_payload)\n",
    "    \n",
    "        if response.status_code == 200:\n",
    "            # Print the response content\n",
    "            response_json = response.json();\n",
    "            # print(response_json)\n",
    "            answer = response_json[\"choices\"][0][\"message\"][\"content\"];\n",
    "            answers = None\n",
    "            return { \"answers\": answer, \"status_code\": response.status_code}\n",
    "        else:\n",
    "            # Print an error message if the request failed\n",
    "            return { \n",
    "            \"status_code\": response.status_code,  \n",
    "            \"message\": response.text\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "353f1014-55cc-4537-97cb-0d18f30e4b5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answers': 'Fast language models are important for several reasons:\\n\\n1. Real-time applications: Fast language models are essential for real-time applications such as speech recognition, machine translation, and text summarization. These applications require models that can process and generate text quickly, often in real-time, to provide a seamless user experience.\\n2. Cost-effective: Fast language models can be more cost-effective than slower models because they require fewer computational resources. This is especially important for large-scale applications that need to process large volumes of data.\\n3. Scalability: Fast language models are more scalable than slower models because they can handle larger datasets and more complex tasks without requiring significant increases in computational resources.\\n4. User experience: Fast language models can provide a better user experience by reducing latency and response times. This is important for applications that require immediate feedback, such as chatbots and virtual assistants.\\n5. Research and development: Fast language models are essential for research and development in natural language processing (NLP) and artificial intelligence (AI). They allow researchers to experiment with larger datasets and more complex models, leading to new breakthroughs and innovations in NLP and AI.\\n\\nIn summary, fast language models are important for real-time applications, cost-effectiveness, scalability, user experience, and research and development. They are essential for the advancement of NLP and AI and have numerous practical applications in various industries.',\n",
       " 'status_code': 200}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await ask_async(GROQ_ENDPOINT, GROQ_MODEL, GROQ_SECRET, question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7c9f8b-0b3b-45d8-ae8e-8c40946a18e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
